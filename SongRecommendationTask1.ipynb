{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Task 2 - Song Recommendation (Part 1)\n",
    "\n",
    "* Irem Ertürk - 03681130 - irem.erturk@tum.de\n",
    "* Tulin Izer  - 03661686 - ga96pav@mytum.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 1: Get input from text file and create COO-matrix M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 300000\n",
    "\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "\n",
    "user_to_row = {}\n",
    "song_to_col = {}\n",
    "user_count = count()\n",
    "song_count = count()\n",
    "\n",
    "with open('train_triplets.txt') as f:\n",
    "    for _ in range(n):\n",
    "        uid, sid, play_count = f.readline().split()\n",
    "        \n",
    "        if not uid in user_to_row:\n",
    "            user_to_row[uid] = next(user_count)\n",
    "        row.append(user_to_row[uid])\n",
    "\n",
    "        if not sid in song_to_col:\n",
    "            song_to_col[sid] = next(song_count)\n",
    "        col.append(song_to_col[sid])        \n",
    "\n",
    "        data.append(float(play_count))  #change as float because otherwise sparse matrix can not be used by svds\n",
    "\n",
    "M = sparse.coo_matrix((data, (row, col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Preprocess the data by binning the play counts into b bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = 10\n",
    "\n",
    "for item, data in enumerate(M.data):\n",
    "    if (data>2**b):\n",
    "        M.data[item] = b\n",
    "    else :\n",
    "        M.data[item] = len(bin(int(data)))-2#because casting the matrix as float I need to cast the data with int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3:Cold Start Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove(A):\n",
    "    csc = A.tocsc()\n",
    "    cf = csc.indptr\n",
    "    keepc = [i for i in range(len(cf)) if i < len(cf)-1 and cf[i+1] - cf[i] > 5]\n",
    "    A = A[:, keepc]\n",
    "    \n",
    "    csr = A.tocsr() \n",
    "    rf = csr.indptr\n",
    "    keepr = [i for i in range(len(rf)) if i < len(rf)-1 and rf[i+1] - rf[i] > 5]\n",
    "    A = A[keepr, :]\n",
    "\n",
    "    if len(keepc) == len(cf)-1 and len(keepr) == len(rf)-1:\n",
    "        return A\n",
    "    return remove(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = remove(M.tocsc())\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4:Test Data Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.nonzero(M)\n",
    "\n",
    "# Create 200 random indices for test data\n",
    "rand = np.random.choice(len(indices[0]), 200, False)\n",
    "\n",
    "test_data = np.zeros((200, 3), dtype=int)\n",
    "\n",
    "for index, r in enumerate(rand):\n",
    "    i = indices[0][r]\n",
    "    j = indices[1][r]\n",
    "    test_data[index] = [i, j, M[i,j]]\n",
    "    M[i, j] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 5: Alternating Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5.1 : Find Q and P^T by SVD decomposition\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "init = 'svd'\n",
    "k = 30 #factors\n",
    "if init == 'svd':#!!Returns U,s and V^T actually and Initialize Q and P\n",
    "    U, s, VT = svds(M, k=k)#Find single value decomposition U Σ and V^T(caution the last term!!)\n",
    "    S = np.diag(s)#Return diagonal matrix format, small s returns vector format\n",
    "    Q = U.dot(S)\n",
    "    PT = VT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Mc = M.tocsc()\n",
    "Mr = M.tocsr()\n",
    "\n",
    "def find_qis(c):\n",
    "    qis_rowindex=[]\n",
    "    col = Mc[:, c]\n",
    "    nz = np.nonzero(col)\n",
    "    ind = nz[0]  #row indeces\n",
    "    #rxis = data[ind]\n",
    "    rxis = np.array(col[nz])[0] \n",
    "    qis_rowindex = Q[ind, :]\n",
    "    return qis_rowindex, rxis\n",
    "\n",
    "def find_pxt(r):\n",
    "    pxt_colindex=[]\n",
    "    row = Mr[r, :]\n",
    "    nz = np.nonzero(row)\n",
    "    ind = nz[1]  #column indices\n",
    "    #rxis = data[ind]\n",
    "    rxis = np.array(row[nz])[0]\n",
    "    ptx_columnindex = PT[:,ind]\n",
    "    return ptx_columnindex, rxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg=linear_model.Ridge(fit_intercept=False)\n",
    "\n",
    "def alternatingOptimization():\n",
    "    for loop in range(10):\n",
    "        #Optimize PT\n",
    "        for x in range(PT.shape[1]):  #(PT.shape[1]):#loop through PT to optimize each ptx column-vector \n",
    "            qis, rxis=find_qis(x)\n",
    "            if len(qis)>0 and len(rxis)> 0:\n",
    "                reg.fit(qis,rxis)\n",
    "                PT[:,x]=np.transpose(reg.coef_)\n",
    "        #Optimize Q\n",
    "        for i in range(Q.shape[0]):  #loop through Q to optimize each qi row-vector  \n",
    "            pxt, rxis=find_pxt(i)       \n",
    "            reg.fit(np.transpose(pxt),rxis)\n",
    "            Q[i,:]=reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alternatingOptimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Step 6: Evaluate Model by Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predicted_values = np.zeros(200, dtype=float)\n",
    "def evaluatemodel(test_data):\n",
    "    for j in range(200):\n",
    "        i = test_data[j,0]#row\n",
    "        x = test_data[j,1]#column\n",
    "        \n",
    "        predicted_values[j] = Q[i,:].dot(PT[:,x])\n",
    "        #print( Q[i,:], PT[:,x])\n",
    "        RMSE=mean_squared_error(np.transpose(test_data[:,2]), predicted_values)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluatemodel(test_data) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
